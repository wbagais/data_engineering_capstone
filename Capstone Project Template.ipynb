{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project uses the Immigration Data and Temperature Data to generate a dataset that will be used by the analyst to answer the following questions:\n",
    "- What are the correlations between destination in the U.S and source climates? \n",
    "- Compare visitors' volume based on arrival time.\n",
    "\n",
    "\n",
    "__The project follows the following steps:__\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "import pyspark.sql.functions as F\n",
    "import datetime\n",
    "import os\n",
    "import configparser\n",
    "import pandas as pd\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.functions import isnan, when, count\n",
    "from pyspark.sql.functions import to_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope  \n",
    "This project work with immigration and temperature data. We will process the ETL using Spark and store the data in a S3 bucket. \n",
    "\n",
    "\n",
    "#### Data Source\n",
    "the project uses the Immigration Data `18-83510-I94-Data-2016/` and Temperature Data `GlobalLandTemperaturesByCity.csv`. Also, we will use `I94_SAS_Labels_Descriptions.SAS` file which describes the immigration data.\n",
    "- I94 Immigration Data: This data comes from the US National Tourism and Trade Office. \n",
    "- World Temperature Data: This dataset came from Kaggle.\n",
    "\n",
    "#### Result tables:\n",
    "- __The Fact Table:__ \n",
    "    - immigration table\n",
    "- __Dimension Tables:__\n",
    "    - date table\n",
    "    - country table\n",
    "    - state table\n",
    "    - temperature table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Data Dictionary: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Describe the __selected__ fields in Immigration dataset.\n",
    "\n",
    "| __Column Name__ | __Description__ |\n",
    "| :--- | :--- |\n",
    "| CICID* | ID that uniquely identify one record in the dataset |\n",
    "| I94YR | 4 digit year |\n",
    "| I94MON | Numeric month |\n",
    "| I94CIT | 3 digit code of source city for immigration (Born country) |\n",
    "| I94RES | 3 digit code of source country for immigration (Residence country) |\n",
    "| ARRDATE | Arrival date in the USA |\n",
    "| I94ADDR | State of arrival |\n",
    "| DEPDATE | Departure date |\n",
    "| DTADFILE | Character Date Field |\n",
    "| VISAPOST | Department of State where where Visa was issued |\n",
    "| OCCUP | Occupation that will be performed in U.S. \n",
    "| BIRYEAR | 4 digit year of birth |\n",
    "| GENDER | Gender |\n",
    "| AIRLINE | Airline used to arrive in U.S. |\n",
    "| FLTNO | Flight number of Airline used to arrive in U.S. |\n",
    "| VISATYPE | Class of admission legally admitting the non-immigrant to temporarily stay in U.S. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Describe the fields in temerature dataset.\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| month | the month |\n",
    "| AverageTemperature | Average temperature of the city in a given month |\n",
    "| Country | Country Name |\n",
    "| Latitude | Latitude |\n",
    "| Longitude | Longitude |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Describe the fields in date dataset.\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| date | Date in format YYYY-MM-DD as a primary key|\n",
    "| day | 2 digits day |\n",
    "| week | 2 digits week |\n",
    "| month | 2 digits month |\n",
    "| year | 4 digits year|\n",
    "| weekday | the day of the week |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Describe the fields in country dataset.\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| code | country code as provided in `I94_SAS_Labels_Descriptions.SAS` file|\n",
    "| country | country name|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Describe the fields in country dataset.\n",
    "\n",
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| code | country code as provided in `I94_SAS_Labels_Descriptions.SAS` file|\n",
    "| state | state name|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore and clean the Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('helpers/dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.jars.packages\",\n",
    "                                        \"saurfang:spark-sas7bdat:2.0.0-s_2.11,org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "    .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read immigration file\n",
    "immigration_file = \"../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\"\n",
    "immigration_df = spark.read.format('com.github.saurfang.sas.spark').load(immigration_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#the selected columns\n",
    "columns = ['cicid','i94yr','i94mon', 'i94cit', 'i94res', 'arrdate', 'i94addr', \n",
    "      'depdate', 'dtadfile', 'visapost', 'occup', 'biryear', 'gender',\n",
    "      'airline', 'fltno', 'visatype']\n",
    "immigration_df = immigration_df[columns]\n",
    "\n",
    "# drop rows where all elements are missing\n",
    "immigration_df = immigration_df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cicid             0\n",
       "i94yr             0\n",
       "i94mon            0\n",
       "i94cit            0\n",
       "i94res            0\n",
       "arrdate           0\n",
       "i94addr      152592\n",
       "depdate      142457\n",
       "dtadfile          1\n",
       "visapost    1881250\n",
       "occup       3088187\n",
       "biryear         802\n",
       "gender       414269\n",
       "airline       83627\n",
       "fltno         19549\n",
       "visatype          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of nulls in each column\n",
    "immigration_df.toPandas().isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+--------+--------+-------+-------+------+-------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|arrdate|i94addr|depdate|dtadfile|visapost|  occup|biryear|gender|airline|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+--------+--------+-------+-------+------+-------+-----+--------+\n",
      "|    0|    0|     0|     0|     0|      0| 152592| 142457|       1| 1881250|3088187|    802|414269|  83627|19549|       0|\n",
      "+-----+-----+------+------+------+-------+-------+-------+--------+--------+-------+-------+------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#number of nulls in each column\n",
    "immigration_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in immigration_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3096313, 16)\n"
     ]
    }
   ],
   "source": [
    "print((immigration_df.count(), len(immigration_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> since the `visapost` and `occup` columns have a lot of nulls we will drop them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We repeated the below step to remove visapost and occup columns from the selected columns\n",
    "#the selected columns\n",
    "columns = ['cicid','i94yr','i94mon', 'i94cit', 'i94res', 'arrdate', 'i94addr', \n",
    "      'depdate', 'dtadfile', 'biryear', 'gender',\n",
    "      'airline', 'fltno', 'visatype']\n",
    "immigration_df = immigration_df[columns]\n",
    "\n",
    "# drop rows where all elements are missing\n",
    "immigration_df = immigration_df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"date\", lambda x: str(pd.to_timedelta(x , unit='D') + pd.Timestamp('1960-1-1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_df.createOrReplaceTempView(\"immigration_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration = spark.sql('''\n",
    "                  SELECT DISTINCT \n",
    "                  int(cicid),\n",
    "                  i94yr,\n",
    "                  i94mon, \n",
    "                  int(i94cit), \n",
    "                  int(i94res), \n",
    "                  date(arrdate) AS arrdate,\n",
    "                  i94addr,\n",
    "                  depdate,\n",
    "                  dtadfile, \n",
    "                  biryear, \n",
    "                  gender,\n",
    "                  airline, \n",
    "                  fltno, \n",
    "                  visatype \n",
    "                  FROM immigration_df\n",
    "                  ORDER BY i94yr, i94mon\n",
    "          '''\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>dtadfile</th>\n",
       "      <th>biryear</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>2016-04-01 00:00:00</td>\n",
       "      <td>GA</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>None</td>\n",
       "      <td>LH</td>\n",
       "      <td>00444</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>469</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>2016-04-01 00:00:00</td>\n",
       "      <td>TN</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00097</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>503</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>2016-04-01 00:00:00</td>\n",
       "      <td>IL</td>\n",
       "      <td>20548.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>00065</td>\n",
       "      <td>WB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>993</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>2016-04-01 00:00:00</td>\n",
       "      <td>NY</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>F</td>\n",
       "      <td>UA</td>\n",
       "      <td>00056</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1111</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>2016-04-01 00:00:00</td>\n",
       "      <td>NY</td>\n",
       "      <td>20554.0</td>\n",
       "      <td>20160401</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>F</td>\n",
       "      <td>UA</td>\n",
       "      <td>02067</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res              arrdate i94addr  \\\n",
       "0     74  2016.0     4.0     103     103  2016-04-01 00:00:00      GA   \n",
       "1    469  2016.0     4.0     103     103  2016-04-01 00:00:00      TN   \n",
       "2    503  2016.0     4.0     103     103  2016-04-01 00:00:00      IL   \n",
       "3    993  2016.0     4.0     104     104  2016-04-01 00:00:00      NY   \n",
       "4   1111  2016.0     4.0     104     104  2016-04-01 00:00:00      NY   \n",
       "\n",
       "   depdate  dtadfile  biryear gender airline  fltno visatype  \n",
       "0  20554.0  20160401   1950.0   None      LH  00444       WT  \n",
       "1  20573.0  20160401   1961.0   None      OS  00097       WT  \n",
       "2  20548.0  20160401   1970.0   None      OS  00065       WB  \n",
       "3  20550.0  20160401   1958.0      F      UA  00056       WT  \n",
       "4  20554.0  20160401   1961.0      F      UA  02067       WT  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: integer (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: integer (nullable = true)\n",
      " |-- i94res: integer (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#save the result in the output folder\n",
    "immigration.write.partitionBy(\"i94yr\", \"i94mon\").parquet('data/output/immigration/', mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperatures table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> Since the date in the temperature table does not match the date in the immigration table. We will take the average per month for each country. Also, We do not need the city column because it is not given in the immigration table.\n",
    " \n",
    " \n",
    " >As a result, we will have the month, country, average temperature, latitude,  and longitude columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read immigration file\n",
    "temperature_file = \"../../data2/GlobalLandTemperaturesByCity.csv\"\n",
    "temperature_df = spark.read.format(\"csv\").options(header='true').load(temperature_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt AverageTemperature AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01              6.068            1.7369999999999999  Århus   \n",
       "1  1743-12-01               None                          None  Århus   \n",
       "2  1744-01-01               None                          None  Århus   \n",
       "3  1744-02-01               None                          None  Århus   \n",
       "4  1744-03-01               None                          None  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df = temperature_df.withColumn('dt',to_timestamp(temperature_df.dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt AverageTemperature AverageTemperatureUncertainty   City  Country  \\\n",
       "0 1743-11-01              6.068            1.7369999999999999  Århus  Denmark   \n",
       "1 1743-12-01               None                          None  Århus  Denmark   \n",
       "2 1744-01-01               None                          None  Århus  Denmark   \n",
       "3 1744-02-01               None                          None  Århus  Denmark   \n",
       "4 1744-03-01               None                          None  Århus  Denmark   \n",
       "\n",
       "  Latitude Longitude  \n",
       "0   57.05N    10.33E  \n",
       "1   57.05N    10.33E  \n",
       "2   57.05N    10.33E  \n",
       "3   57.05N    10.33E  \n",
       "4   57.05N    10.33E  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df.createOrReplaceTempView(\"temperature_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature = spark.sql(\"\"\"\n",
    "    SELECT DISTINCT \n",
    "    Country,\n",
    "    month(dt) AS Month,\n",
    "    AVG(AverageTemperature) as AverageTemperature, \n",
    "    FIRST(Latitude) AS Latitude, \n",
    "    fIRST(Longitude) AS Longitude\n",
    "    FROM temperature_df\n",
    "    GROUP BY Month, Country\n",
    "    ORDER BY Country, Month\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Month</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607802</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2</td>\n",
       "      <td>2.842286</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>3</td>\n",
       "      <td>8.142778</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4</td>\n",
       "      <td>14.090881</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>5</td>\n",
       "      <td>19.884800</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>69.61E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  Month  AverageTemperature Latitude Longitude\n",
       "0  Afghanistan      1            0.607802   36.17N    69.61E\n",
       "1  Afghanistan      2            2.842286   36.17N    69.61E\n",
       "2  Afghanistan      3            8.142778   36.17N    69.61E\n",
       "3  Afghanistan      4           14.090881   36.17N    69.61E\n",
       "4  Afghanistan      5           19.884800   36.17N    69.61E"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#save the result in the output folder as parquet\n",
    "temperature.write.parquet('data/output/temperature', mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#save the result in the output folder as CSV\n",
    "temperature.coalesce(1).write.format('com.databricks.spark.csv').save('data/output/temperature',header = 'true', mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Date tabe\n",
    "Extract the date from the arrival column in the immigration table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "date = spark.sql('''\n",
    "                  SELECT DISTINCT \n",
    "                  date,\n",
    "                  dayofmonth(date) AS day,\n",
    "                  weekofyear(date) AS week,\n",
    "                  month(date) AS month,\n",
    "                  year(date) AS year,\n",
    "                  dayofweek(date) AS weekday\n",
    "                  FROM (SELECT date(arrdate) AS date FROM immigration_df)\n",
    "          '''\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-08 00:00:00</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-22 00:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-24 00:00:00</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-29 00:00:00</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-10 00:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  day  week  month  year  weekday\n",
       "0  2016-04-08 00:00:00    8    14      4  2016        6\n",
       "1  2016-04-22 00:00:00   22    16      4  2016        6\n",
       "2  2016-04-24 00:00:00   24    16      4  2016        1\n",
       "3  2016-04-29 00:00:00   29    17      4  2016        6\n",
       "4  2016-04-10 00:00:00   10    14      4  2016        1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#save the result in the output folder\n",
    "date.coalesce(1).write.format('com.databricks.spark.csv').save('data/output/date',header = 'true', mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Country tabe\n",
    "No editing needed. We are only going to copy the country table to the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read country file\n",
    "country_file = \"data/countries.csv\"\n",
    "country = spark.read.format(\"csv\").options(header='true').load(country_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code       country\n",
       "0  582        MEXICO\n",
       "1  236   AFGHANISTAN\n",
       "2  101       ALBANIA\n",
       "3  316       ALGERIA\n",
       "4  102       ANDORRA"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#save the result in the output folder\n",
    "country.coalesce(1).write.format('com.databricks.spark.csv').save('data/output/country',header = 'true', mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### state tabe\n",
    "No editing needed. We are only going to copy the state table to the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read country file\n",
    "state_file = \"data/states.csv\"\n",
    "state = spark.read.format(\"csv\").options(header='true').load(state_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code       state\n",
       "0   AL     ALABAMA\n",
       "1   AK      ALASKA\n",
       "2   AZ     ARIZONA\n",
       "3   AR    ARKANSAS\n",
       "4   CA  CALIFORNIA"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#save the result in the output folder\n",
    "state.coalesce(1).write.format('com.databricks.spark.csv').save('data/output/state',header = 'true', mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "<img src=\"images/ER_diagram.png\" alt=\"ER_diagram\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The model used the immigration dataset as a star-table. For simplicity, we will work on Apr data only. However, later we can run the code on all the datasets. We only select the data that is related to the analyst purpose. Using the arrival date, the date table created. \n",
    "\n",
    "\n",
    "The country and state tables, there are created from the data dictionary.\n",
    "\n",
    "\n",
    "The temperature table grouped by month and country. Since the date in the temperature table does not match the date in the immigration table. We will take the average per month for each country. Also, We do not need the city column because it is not given in the immigration table. As a result, we will have the month, country, average temperature, latitude,  and longitude columns only.\n",
    "\n",
    "The country table will be the bridge between the immigration and temperature table, which will allow the analyst to identify the correlation between the arrival and country of residency.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "The pipeline steps are:\n",
    "- Load the datasets\n",
    "- Clean the data using spark and save the result into S3 bucket\n",
    "- quality test for the data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The code in this notebook saves the result locally. However, the final code is store in `etl.py`. By running this file, the result will be saved in S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "`etl.py` file include the following functions: \n",
    "- create_spark_session()\n",
    "    - return: spark session\n",
    "-  process_immigration_data(spark, input_data, output_data)\n",
    "    - this function  read the original immigration data and write the final immigration and date data into the s3bucket\n",
    "- process_temperature_data(spark, input_data, output_data) \n",
    "    - this function  read the original temperature data and write the final temerature data into the s3bucket\n",
    "- process_country_data(spark, input_data, output_data)\n",
    "    - this function  copy the country table into the s3bucket\n",
    "- process_state_data(spark, input_data, output_data)\n",
    "    - this function  copy the state table into the s3bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#before runing this cell run (aws configure) in terminal\n",
    "# Write code here\n",
    "#!python etl.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "For data quality we will check two things:\n",
    " * the data is not dublicated based on selected columns\n",
    " * If the records is greated than 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#the quality check function\n",
    "def quality_check(path, table, columns):\n",
    "    df_spark=spark.read.parquet(path)\n",
    "    if int(df_spark.count()) < 1:\n",
    "        print(f\"Data quality check for {table} failed. {table} returned no results\")\n",
    "    else:\n",
    "        print(f\"Data quality check for {table} Success. {table} has {int(df_spark.count())} records\")\n",
    "        \n",
    "    if df_spark.count() > df_spark.dropDuplicates(columns).count():\n",
    "        print(f'{table} has duplicates rows')\n",
    "    else: \n",
    "        print(f'{table} has no duplicate rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check for immigration Success. immigration has 3096313 records\n",
      "immigration has no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# immigration data check\n",
    "path = \"s3a://wejdan-dend/output/immigration\"\n",
    "table = \"immigration\"\n",
    "columns = ['cicid']\n",
    "quality_check(path, table, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check for date Success. date has 30 records\n",
      "date has no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# date data check\n",
    "path = \"s3a://wejdan-dend/output/date\"\n",
    "table = \"date\"\n",
    "columns = ['date']\n",
    "quality_check(path, table, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check for temperature Success. temperature has 1908 records\n",
      "temperature has no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# temperature data check\n",
    "path = \"s3a://wejdan-dend/output/temperature\"\n",
    "table = \"temperature\"\n",
    "columns = ['Country', 'Month']\n",
    "quality_check(path, table, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check for country Success. country has 289 records\n",
      "country has no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# Contry data check\n",
    "path = \"s3a://wejdan-dend/output/country\"\n",
    "table = \"country\"\n",
    "columns = ['code']\n",
    "quality_check(path, table, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check for state Success. state has 55 records\n",
      "state has no duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# state data check\n",
    "path = \"s3a://wejdan-dend/output/state\"\n",
    "table = \"state\"\n",
    "columns = ['code']\n",
    "quality_check(path, table, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Please check the data dictionary section under the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "I used spark because it will be easy to move the code into the EMR cluster later. The data do not need to be updated frequently. This analysis is done based on request. Therefore, we did not use airflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " A description of how we would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "     * we will run the code in EMR cluster. \n",
    " * The data populates a dashboard that must be updated on a daily basis by 7 am every day.\n",
    "     * We will use the airflow to schedule and run the pipeline. By creating a dag that read data from S3 and process the ETL and the data quality. Then save the data in A S3 bucket\n",
    " * The database needed to be accessed by 100+ people.\n",
    "     * we will use Amazon Redshift "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
